[
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "",
    "text": "Show the code\nimport pandas as pd \nimport numpy as np\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots"
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "project 5",
    "section": "",
    "text": "This analysis is intended to analyze how the entertainment industry invests its resources in different areas and how these impact its success. It also focuses on analyzing what audience they are trying to attract and how the genre of the movie or series impacts its success.\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown\nfrom datetime import datetime\n\n\ndef load_data(file_path):\n\n    \"\"\"\n    Load data from a CSV file and convert 'Year' column.\n    \n    Parameters CSV file to read.\n    \n    Return: The CSV file.\n    \"\"\"\n\n    df = pd.read_csv(file_path)\n    if 'Year' in df.columns:\n        df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n    return df\n\n# Load the datasets\ndf_genre = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vRk4N_qCsv9odv-caI5zD3l1LU1RUQAB8dBTSa7I3SdWM7UjPCHRE_omcKzDsDpejH6tqXirzMl0UzR/pub?gid=968459257&single=true&output=csv')\ndf_movies_data = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vSOuzSVo0aXNE5Hmg8NYuxGAPoP_NoNrVpjDcpctDOWt0PGWy1AdAkB1GEJkGho5whz6T8HGkSbV0Vu/pub?gid=1082575037&single=true&output=csv')\ndf_movies = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vQHKR-czBp8PJ04SfA58SOc6bhF297FP63w6-lvyvJVZyMDoAsjQjdTQgnfKiMYC7Z83xolXWKiWzaz/pub?gid=302209156&single=true&output=csv')\n\n\n\nThis section analyzes each streaming platform, because each platform has many shows, some better known than others. It is established that having a Rating above 6 points is the most ideal. This shows that the platform generally offers content that the standard customer consumes.\n\nShow the code\ndef average_rating_by_service(df):\n\n    \"\"\"\n    Calculate the average rating for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    avg_rating = df.groupby('Streaming_Name')['Rating'].mean().sort_values(ascending=False)\n    \n    display(avg_rating)\n    \n    plt.figure(figsize=(12, 6))\n    avg_rating.plot(kind='bar')\n    plt.title('Rating by Streaming Service')\n    plt.xlabel('Streaming Service')\n    plt.ylabel('Average Rating')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('avg_rating_by_service.png')\n    plt.close()\n    display(Markdown(\"#### Average Rating by Streaming Service\"))\n    display(Markdown(\"![Average Rating by Streaming Service](avg_rating_by_service.png)\"))\n\naverage_rating_by_service(df_genre)\n\nStreaming_Name\nHulu           6.330145\nDisney+        6.180337\nNetflix        6.045523\nPrime Video    5.423707\nName: Rating, dtype: float64\n\n\n\n\n\nAverage Rating by Streaming Service\n\n\n\n\n\n\nI wanted to show how meany shows each streming service offere to their clients. Keep in mind that some streming services offered different titles per region which might increase the number of shows in general. \n\nShow the code\ndef titles_per_service(df):\n\n    \"\"\"\n    Count Number of titles for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    title_count = df['Streaming_Name'].value_counts()\n    \n    display(title_count)\n    \n    plt.figure(figsize=(12, 6))\n    title_count.plot(kind='bar')\n    plt.title('Number of Titles per Streaming Service')\n    plt.xlabel('Streaming Service')\n    plt.ylabel('Number of Titles')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('titles_per_service.png')\n    plt.close()\n    display(Markdown(\"#### Number of Titles per Streaming Service\"))\n    display(Markdown(\"![Number of Titles per Streaming Service](titles_per_service.png)\"))\n\ntitles_per_service(df_genre)\n\nStreaming_Name\nPrime Video    1856\nNetflix        1731\nDisney+         712\nHulu            690\nName: count, dtype: int64\n\n\n\n\n\nNumber of Titles per Streaming Service\n\n\n\n\n\n\n_This section shows a general summary of how the viwers rate each streming service. This was accomplish by taking all the votes for each show and divide them by each streming service. This let us know that all streming service have great succeses and failus, but it was Hulu the one that shous a slitly higher result compare to the others.\n\nShow the code\ndef rating_distribution_by_service(df):\n\n    \"\"\"\n    Display Rating for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    display(df.groupby('Streaming_Name')['Rating'].describe())\n    \n    plt.figure(figsize=(12, 6))\n    df.boxplot(column=['Rating'], by='Streaming_Name', figsize=(12, 6))\n    plt.suptitle('') \n    plt.xlabel('Streaming Service')\n    plt.ylabel('Rating')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('rating_distribution.png')\n    plt.close()\n\n    display(Markdown(\"![Rating Distribution by Streaming Service](rating_distribution.png)\"))\n\nrating_distribution_by_service(df_genre)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nStreaming_Name\n\n\n\n\n\n\n\n\n\n\n\n\nDisney+\n712.0\n6.180337\n1.303800\n1.0\n5.3\n6.1\n7.1\n9.6\n\n\nHulu\n690.0\n6.330145\n1.087075\n1.5\n5.6\n6.4\n7.1\n9.4\n\n\nNetflix\n1731.0\n6.045523\n1.099635\n1.2\n5.2\n6.0\n6.9\n9.8\n\n\nPrime Video\n1856.0\n5.423707\n1.182801\n1.2\n4.4\n5.4\n6.2\n9.3\n\n\n\n\n\n\n\n\n\nRating Distribution by Streaming Service\n\n\n&lt;Figure size 1152x576 with 0 Axes&gt;\n\n\n\nThis section shows that the average rating per show has decrease in the last couple years but resently has experience a significant recovery, this could be because the Covid 19 many people start to watch way more shows thorugh streming services.\n\nShow the code\ndef average_rating_by_year(df):\n\n    \"\"\"\n    Calculate Average rating by year from 2000 to 2021.\n    \n    Parameters\n        'Year' and 'Rating' columns.\n    \n    Return: Chart\n    \"\"\"\n\n    # Convert Year to datetime if it's not already\n    if not pd.api.types.is_datetime64_any_dtype(df['Year']):\n        df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n    \n    # Filter for years 2000 to 2021\n    df_filtered = df[(df['Year'].dt.year &gt;= 2000) & (df['Year'].dt.year &lt;= 2021)]\n    \n    yearly_avg_rating = df_filtered.groupby(df_filtered['Year'].dt.year)['Rating'].mean()\n    \n    plt.figure(figsize=(12, 6))\n    yearly_avg_rating.plot(kind='line')\n    plt.title('Average Rating by Year (2000-2021)')\n    plt.xlabel('Year')\n    plt.ylabel('Average Rating')\n    plt.xlim(2000, 2021)\n    plt.tight_layout()\n    plt.savefig('avg_rating_by_year.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Rating by Year (2000-2021)\"))\n    display(Markdown(\"![Average Rating by Year](avg_rating_by_year.png)\"))\n\naverage_rating_by_year(df_genre)\n\n\n\n\n\n\nAverage Rating by Year\n\n\n\n\n\n\nI wanted to show that even if in general more people were whaching more shows through steming, because of covid the number of new shows drasticly decresed.\n\nShow the code\ndef titles_by_year(df):\n\n    \"\"\"\n    Count Number of titles by year.\n    \n    Parameters\n        'Year' column.\n    \n    Return: Chart\n    \"\"\"\n    yearly_title_count = df.groupby(df['Year'].dt.year).size()\n\n    plt.figure(figsize=(12, 6))\n    yearly_title_count.plot(kind='line')\n    plt.title('Number of Titles by Year')\n    plt.xlabel('Year')\n    plt.ylabel('Number of Titles')\n    plt.tight_layout()\n    plt.savefig('titles_by_year.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Number of Titles by Year\"))\n    display(Markdown(\"![Number of Titles by Year](titles_by_year.png)\"))\n\ntitles_by_year(df_genre)\n\n\n\n\n\n\nNumber of Titles by Year\n\n\n\n\n\n\nWe can see that the number of shows directed to a adult audience have take a significate percentange of space in each strming plataform. Something to concider if you have a family and do not which to expose your children or minors to such content.\n\nShow the code\ndef shows_by_age_group(df):\n\n    \"\"\"\n    Count Number of shows by age\n    \n    Parameters\n        'Age' column.\n    \n    Return: Chart.\n    \"\"\"\n\n    age_count = df['Age'].value_counts().sort_index()\n    \n    display(Markdown(\"### Number of Shows by Age Group\"))\n    display(Markdown(\"#### Table: Shows by Age Group\"))\n    display(age_count)\n    \n    plt.figure(figsize=(12, 6))\n    age_count.plot(kind='bar')\n    plt.title('Number of Shows by Age Group')\n    plt.xlabel('Age Group')\n    plt.ylabel('Number of Shows')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('shows_by_age_group.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Shows by Age Group\"))\n    display(Markdown(\"![Shows by Age Group](shows_by_age_group.png)\"))\n\nshows_by_age_group(df_genre)\n\n\n\n\n\n\nAge\n13+     945\n16+     251\n18+    2116\n7+     1018\nall     659\nName: count, dtype: int64\n\n\n\n\n\n\nShows by Age Group\n\n\n\n\n\n\n_Moving to the movies analysis, I first wanted to show the top 10 genres in which the entretement indurstry has expent more of their resorces and later analyze if their investments were smart or not. I used the data base for rotten tomatoes and compared to the data in IMB to have both perspectives.\n\n\nShow the code\ndef analyze_genres(df_movies_data, df_movies):\n\n    \"\"\"\n    Analyze Genre from different datasets.\n    \n    Parameters\n        df_movies_data: space-separated.\n        df_movies: comma-separated.\n    \n    Return: Chart\n    \"\"\"\n\n    # Function to split genres and count for movies_data.csv (space-separated)\n    def count_genres_space(series):\n        genre_list = []\n        for genres in series:\n            if isinstance(genres, str):\n                genre_list.extend([genre.strip() for genre in genres.split()])\n        return pd.Series(genre_list).value_counts()\n    \n    # Function to split genres and count for movies.csv (comma-separated)\n    def count_genres_comma(series):\n        genre_list = []\n        for genres in series:\n            if isinstance(genres, str):\n                genre_list.extend([genre.strip() for genre in genres.split(',')])\n        return pd.Series(genre_list).value_counts()\n    \n    # Analyze genres from movies_data.csv\n    genres_movies_data = count_genres_space(df_movies_data['genres'])\n    genres_movies_data = genres_movies_data.nlargest(10)  # Get top 10 genres\n    \n    # Analyze genres from movies.csv\n    genres_movies = count_genres_comma(df_movies['genres'])\n    genres_movies = genres_movies.nlargest(10)  # Get top 10 genres\n    \n    display(genres_movies_data)\n    \n    plt.figure(figsize=(12, 8))\n    genres_movies_data.plot(kind='bar')\n    plt.title('Top 10 Genres in Movies (Rotten Tomatoes)')\n    plt.xlabel('Genre')\n    plt.ylabel('Number of Movies')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('genres_movies_data.png')\n    plt.close()\n    display(Markdown(\"#### Top 10 Genres\"))\n    display(Markdown(\"![Top 10 Genres](genres_movies_data.png)\"))\n    \n    # Display results for movies.csv\n\n    display(genres_movies)\n    \n    plt.figure(figsize=(12, 8))\n    genres_movies.plot(kind='bar')\n    plt.title('Top 10 Genres in Movies (IMB)')\n    plt.xlabel('Genre')\n    plt.ylabel('Number of Movies')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('genres_movies.png')\n    plt.close()\n    display(Markdown(\"#### Top 10 Genres\"))\n    display(Markdown(\"![Top 10 Genres](genres_movies.png)\"))\n\nanalyze_genres(df_movies_data, df_movies)\n\n\nDrama,        2249\nAction,       2134\nComedy,       1909\nDrama         1555\nAdventure,    1400\nThriller      1344\nScience       1199\nAnimation,    1136\nThriller,      980\nRomance        953\nName: count, dtype: int64\n\n\n\n\n\n\n\n\nTop 10 Genres\n\n\n\n\nDocumentary      95072\nDrama            80108\nComedy           46886\nAnimation        22312\nMusic            17930\nHorror           13562\nDrama-Romance     8246\nComedy-Drama      7704\nAction            5978\nThriller          5512\nName: count, dtype: int64\n\n\n\n\n\n\n\n\nTop 10 Genres\n\n\n\n\n\n\n\nThis section now limits the results for the past 24 years that shows that overall the industry is still offering in general waht the viwers want to watch but that genes as documentaris and comedy have lost some value in the viwers pespective. We need to keep in mind that their are still many of this genres that are succesfull and that this analysis just takes an overall pespective of what the viwers value the most.\n\n\nShow the code\ndef vote_average_by_genre_cleaned_movies(df):\n\n    \"\"\"\n    Calculate Aaverage vote by genre for movies from 2000 to 2024.\n    \n    Parameters\n        'release_date', 'genres', and 'vote_average' columns.\n    \n    Return: Chart.\n    \"\"\"\n\n    # Convert release_date to datetime\n    df['release_date'] = pd.to_datetime(df['release_date'])\n    \n    # Filter for movies from 2000 to 2024\n    df_filtered = df[(df['release_date'].dt.year &gt;= 2000) & (df['release_date'].dt.year &lt;= 2024)]\n    \n    # Split genres and explode the dataframe\n    df_exploded = df_filtered.assign(genres=df_filtered['genres'].str.split('-')).explode('genres')\n    \n    # Group by genre and calculate mean vote_average\n    vote_avg_by_genre = df_exploded.groupby('genres')['vote_average'].mean().sort_values(ascending=False)\n    \n    # Get top 10 genres\n    top_10_genres = vote_avg_by_genre.head(10)\n    \n    display(Markdown(\"### Vote Average by Genre (2000-2024)\"))\n    display(Markdown(\"#### Table: Average Vote by Genre (Top 10)\"))\n    display(top_10_genres)\n    \n    plt.figure(figsize=(12, 6))\n    top_10_genres.plot(kind='bar')\n    plt.title('Average Vote by Genre (Top 10, 2000-2024)')\n    plt.xlabel('Genre')\n    plt.ylabel('Average Vote')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('vote_average_by_genre_cleaned_movies.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Vote by Genre (Top 10, 2000-2024)\"))\n    display(Markdown(\"![Average Vote by Genre](vote_average_by_genre_cleaned_movies.png)\"))\n\n# Assuming df_cleaned_movies is already loaded\nvote_average_by_genre_cleaned_movies(df_movies)\n\n\n\n\n\n\n\n\ngenres\nTV Movie     4.746888\nAdventure    4.491628\nAction       4.213902\nCrime        4.186147\nThriller     4.166371\nFamily       4.119148\nWar          4.070821\nHistory      4.019655\nRomance      4.016598\nMystery      3.968000\nName: vote_average, dtype: float64\n\n\n\n\n\n\n\n\nAverage Vote by Genre\n\n\n\n\n\n\n\nMany people used to tell me that if a movie spent a lot of many of makes a lot of money it will be good. We can see now that that is not correct. The correlation shows that in many cases the budget and revenew will afect one another, but concerning movie quality or succes in satisfiing the viwers, their is not correlation between the budget or revenue witht he Vote Average that the viwers give to the movie.\n\n\nShow the code\n#In case I wanted to calculated revenue in the future\ndef revenue_by_genre(df):\n\n    \"\"\"\n    Calculate Average revenue by genre.\n    \n    Parameters\n        'genres' and 'revenue' columns.\n    \n    Return: Chart\n    \"\"\"\n\n    # Split the genres and explode the dataframe\n    df_exploded = df.assign(genres=df['genres'].str.split(',')).explode('genres')\n    \n    # Group by genre and calculate mean revenue\n    revenue_by_genre = df_exploded.groupby('genres')['revenue'].mean().sort_values(ascending=False)\n    \n    display(Markdown(\"### Revenue by Genre\"))\n    display(Markdown(\"#### Table: Average Revenue by Genre\"))\n    display(revenue_by_genre)\n    \n    plt.figure(figsize=(12, 6))\n    revenue_by_genre.plot(kind='bar')\n    plt.title('Average Revenue by Genre')\n    plt.xlabel('Genre')\n    plt.ylabel('Average Revenue')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('revenue_by_genre.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Revenue by Genre\"))\n    display(Markdown(\"![Average Revenue by Genre](revenue_by_genre.png)\"))\n\ndef revenue_by_production_company(df):\n    # Split the production companies and explode the dataframe\n    df_exploded = df.assign(production_companies=df['production_companies'].str.split(',')).explode('production_companies')\n    \n    # Group by production company and calculate mean revenue\n    revenue_by_company = df_exploded.groupby('production_companies')['revenue'].mean().sort_values(ascending=False).head(20)\n    \n    display(Markdown(\"### Revenue by Production Company\"))\n    display(Markdown(\"#### Table: Average Revenue by Production Company (Top 20)\"))\n    display(revenue_by_company)\n    \n    plt.figure(figsize=(12, 6))\n    revenue_by_company.plot(kind='bar')\n    plt.title('Average Revenue by Production Company (Top 20)')\n    plt.xlabel('Production Company')\n    plt.ylabel('Average Revenue')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('revenue_by_production_company.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Revenue by Production Company (Top 20)\"))\n    display(Markdown(\"![Average Revenue by Production Company](revenue_by_production_company.png)\"))\n\ndef vote_average_by_genre_10(df):\n    # Split the genres and explode the dataframe\n    df_exploded = df.assign(genres=df['genres'].str.split(',')).explode('genres')\n    \n    # Group by genre and calculate mean vote_average\n    vote_avg_by_genre = df_exploded.groupby('genres')['vote_average'].mean().sort_values(ascending=False)\n    \n    # Get top 10 genres\n    top_10_genres = vote_avg_by_genre.head(10)\n\n\ndef correlation_analysis(df):\n    # Calculate correlations\n    corr_budget_revenue = df['budget'].corr(df['revenue'])\n    corr_budget_vote = df['budget'].corr(df['vote_average'])\n    corr_revenue_vote = df['revenue'].corr(df['vote_average'])\n    \n    display(Markdown(\"### Correlation Analysis\"))\n    display(Markdown(f\"Correlation between Budget and Revenue: {corr_budget_revenue:.2f}\"))\n    display(Markdown(f\"Correlation between Budget and Vote Average: {corr_budget_vote:.2f}\"))\n    display(Markdown(f\"Correlation between Revenue and Vote Average: {corr_revenue_vote:.2f}\"))\n    \n    # Scatter plots\n    plt.figure(figsize=(18, 6))\n    \n    plt.subplot(131)\n    plt.scatter(df['budget'], df['revenue'])\n    plt.title('Budget vs Revenue')\n    plt.xlabel('Budget')\n    plt.ylabel('Revenue')\n    \n    plt.subplot(132)\n    plt.scatter(df['budget'], df['vote_average'])\n    plt.title('Budget vs Vote Average')\n    plt.xlabel('Budget')\n    plt.ylabel('Vote Average')\n    \n    plt.subplot(133)\n    plt.scatter(df['revenue'], df['vote_average'])\n    plt.title('Revenue vs Vote Average')\n    plt.xlabel('Revenue')\n    plt.ylabel('Vote Average')\n    \n    plt.tight_layout()\n    plt.savefig('correlation_analysis.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Correlation Analysis\"))\n    display(Markdown(\"![Correlation Analysis](correlation_analysis.png)\"))\n\n# Run the analyses\nvote_average_by_genre_10(df_movies)\ncorrelation_analysis(df_movies)\n\n\n\n\n\nCorrelation between Budget and Revenue: 0.50\n\n\nCorrelation between Budget and Vote Average: 0.06\n\n\nCorrelation between Revenue and Vote Average: 0.07\n\n\n\n\n\n\n\n\nCorrelation Analysis"
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "Brian Munoz",
    "section": "",
    "text": "I recently change my major to Business Analytics, but the data part is what catch my attention. I love to know why things happen, and even better how can I make them happen. Data does not only explain thinks around us, but has the potential to guide people and organizations to make smart decitions that will allow them to grow and become something even better. \n\n\nI am still learning, I am very new in python and the other programing languges. Nevertheless, I love how just some simple commands can provide you a whole different pespective of a specific scenario. Data is everywhere, movies, games, politics, etc…\nData can allow us to solve simple, and even very complecated problems. We just need to know how to explore it and how to interpretate it. Is like learning a whole different language, the language of data, the language of answers.\nMarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Analytics Intern\nBountiful, UT | 385-299-5344 | brianmunozr@gmail.com | LinkedIn\n\n\nWith 3+ years of experience in data collection and analysis, my primary focus is driving informed decision-making through rigorous examination of complex datasets. I specialize in developing and implementing advanced analytical models, data visualization, translating findings into clear, strategic recommendations, and empowering teams to leverage data for goal achievement.\nMy expertise includes creating innovative strategies to expand client reach and improve existing projects. I aim to uncover valuable insights that propel companies and their workforce towards sustainable success.\n\n\n\n\n\nBrigham Young University Idaho | Rexburg, ID | 05/2023 - Present\n\nAssist 50+ students and created personal reports for each one of them.\nUse Excel and SQL queries to provide an understanding of the students individual results and improvements.\nUse advanced Excel skills to create personalized improvement plans for students based on collected historical performance data available.\n\n\n\n\nBrigham Young University | Rexburg, ID | 09/2021 - 04/2023\n\nEnhanced student academic progress by 25-35% by conducting predictive and diagnostic analysis via surveys.\nFacilitated improved communication channels between full-time advisors and part-time advisors.\nManage high-risk scenarios by maintaining comprehensive records to devise satisfactory resolutions for students.\nConducted performance analysis of 25 employees utilizing Excel-generated reports and provide plans of improvement.\n\n\n\n\nThe Church of Jesus Christ of LDS | Morristown, NJ | 02/2018 - 02/2020\n\nEnhanced community development in 10+ New Jersey localities by developing over 100 tailored English lesson plans and strategic.\nConducted training sessions for teams of 6 to 10 members to enhance organizational performance during community events.\nCultivate strong rapport with key stakeholders and local leaders, and evaluated program accomplishments by analyzing and documenting data for participants and reports.\n\n\n\n\nLa Tienda | Guatemala City, Guatemala | 2016 - 2017\n\nManage purchases and sales of the business and structure a growth plan through the collection and analysis of sales history data.\nCollects data to evaluate possible future products to increase profits and decrease costs.\n\n\n\n\n\nBachelor in Business Analytics\nBrigham Young University-Idaho | Rexburg, ID | 09/2020 - 04/2025\n\n\n\nPower BI, SQL, Microsoft Office, Python, Windows, Excel, Mac OS, Performance analysis, Leadership, Communication, Data Analysis, Problem Solving, Critical Thinking, Entrepreneurial\n\n\n\n\nSpanish: Native\nEnglish: Proficient\n\n\n\n\nConflict resolution: Conducting thorough analysis, exploring viable solutions, and providing comprehensive reports to leadership to ensure informed decision-making and strategic action.\n\n\n\nProductivity improvement: Through extensive experimentation and iterative processes, I gained a comprehensive understanding of my team’s strengths and limitations. As a result, we significantly enhanced our operational efficiency and produced more comprehensive reports, thereby facilitating informed decision-making at the executive level.\n\n\n\n\nData-driven decision-making\nPuzzles"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "Standing on the shoulders of giants\n\n\nLaws of motion, gravitation, minting coins, disliking Robert Hooke\n\n\n\nCooling, power series, optics, alchemy, planetary motions, apples."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Bachelor in Business Analytics\nBrigham Young University-Idaho | Rexburg, ID | 09/2020 - 04/2025"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "2012 President, Royal Society, London, UK\nAssociate, French Academy of Science, Paris, France"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1669 Newton Sir I, De analysi per æquationes numero terminorum infinitas.\n1669 Lectiones opticæ.\netc. etc. etc.\n\n\n\n2012 Infinitesimal calculus for solutions to physics problems, SMBC patent 001"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Isaac Newtons’s CV",
    "section": "",
    "text": "1600 Royal Mint, London\n\nWarden\nMinted coins\n\n1600 Lucasian professor of Mathematics, Cambridge University"
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "",
    "text": "Read and format project data\nurl = \"https://raw.githubusercontent.com/byuidatascience/data4dwellings/master/data-raw/dwellings_denver/dwellings_denver.csv\"\ndf = pd.read_csv(url)\ndf['before1980'] = df['yrbuilt'] &lt; 1980"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "The relationship between movies and names is not as strong as many might think. While we can also verify that the influence of religious figures has weakened in recent years when naming people with said names.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "",
    "text": "Show the code\nimport pandas as pd \nimport numpy as np\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots"
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#elevator-pitch",
    "href": "Cleansing_Exploration/project1.html#elevator-pitch",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "The relationship between movies and names is not as strong as many might think. While we can also verify that the influence of religious figures has weakened in recent years when naming people with said names.\n\n\nRead and format project data\n# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html\n\n# Include and execute your code here\ndf = pd.read_csv(\"https://raw.githubusercontent.com/byuidatascience/data4names/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#questiontask-1",
    "href": "Cleansing_Exploration/project1.html#questiontask-1",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n# Filter the DataFrame for the name 'Brian'\nbrian_data = df[df['name'] == 'Brian']\n\n# Reshape the data\nmelted_brian_data = brian_data.melt(id_vars=['name', 'year'], var_name='state', value_name='count')\n\n# Aggregate the data\naggregated_brian_data = melted_brian_data.groupby(['year'])['count'].sum().reset_index()\n\n# Create the interactive line plot\nfig = px.line(aggregated_brian_data, x='year', y='count', title='Usage of the Name \"Brian\" Over Time')\n\n# Update the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Count',\n    font=dict(size=14)\n)\n\n# Display the plot\nfig.show()\n\n\n                                                \n\n\nHere is another table using the scatter chart and a trend line:\n\n\nRead and format data\n# Include and execute your code here\n\n# Filter the DataFrame for the name 'Brian'\nbrian_data = df[df['name'] == 'Brian']\n\n# Reshape the data\nmelted_brian_data = brian_data.melt(id_vars=['name', 'year'], var_name='state', value_name='count')\n\n# Aggregate the data\naggregated_brian_data = melted_brian_data.groupby(['year'])['count'].sum().reset_index()\n\n# Create the scatter plot with a trendline\nfig = px.scatter(aggregated_brian_data, x='year', y='count', trendline='lowess', title='Usage of the Name \"Brian\" Over Time')\n\n# Update the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Total Count',\n    font=dict(size=14)\n)\n\n# Display the plot\nfig.show()"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#questiontask-2",
    "href": "Cleansing_Exploration/project1.html#questiontask-2",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nIf a Brittany contact me at the precent moment (2024), base on the data we could said that the most lickly age could be in between the ages of 34 - 24.\n\n\nplot example\nbrittany_data = df[df['name'] == 'Brittany']\n\n# Create a scatter plot using Plotly Express\nfig = px.scatter(brittany_data, x='year', y='Total', title='Usage of the name \"Brittany\" over the years')\nfig.update_layout(xaxis_title='Year', yaxis_title='Total')\n\nfig.add_vline(x=1980, line_width=2, line_color=\"red\",  line_dash=\"dash\")\n\nfig.add_vline(x=2000, line_width=2, line_color=\"red\",  line_dash=\"dash\")\n\nfig.show()\n\n\n                                                \nMy useless chart"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#questiontask-3",
    "href": "Cleansing_Exploration/project1.html#questiontask-3",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nIt seems that the number of people with any of this realigious names have drasticly decrease as time goes by.\n\n\nplot example\n# Filter the data for the names and year range\nnames = ['Mary', 'Martha', 'Peter', 'Paul']\nfiltered_data = df[df['name'].isin(names) & (df['year'] &gt;= 1920) & (df['year'] &lt;= 2000)]\n\n# Reshape the data\nmelted_data = filtered_data.melt(id_vars=['name', 'year'], var_name='state', value_name='count')\n\n# Aggregate the data\naggregated_data = melted_data.groupby(['name', 'year'])['count'].sum().reset_index()\n\n# Create the line plot\nfig = px.line(aggregated_data, x='year', y='count', color='name', title='Name Usage of Mary, Martha, Peter, and Paul (1920-2000)')\n\n# Update the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Total Count',\n    font=dict(size=14),\n    legend=dict(title='Name')\n)\n\nfig.show()\n\n\n                                                \nMy useless chart"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#questiontask-4",
    "href": "Cleansing_Exploration/project1.html#questiontask-4",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI decided to use the name Kevin from the movie Home Alone to see if the movie affected the number of boys named Kevin increase after the movie came out\n\n\nRead and format data\n# Include and execute your code here\n\nnames = ['Kevin']\nfiltered_data = df[df['name'].isin(names) & (df['year'] &gt;= 1920) & (df['year'] &lt;= 2020)]\n\n# Reshape the data\nmelted_data = filtered_data.melt(id_vars=['name', 'year'], var_name='state', value_name='count')\n\n# Aggregate the data\naggregated_data = melted_data.groupby(['name', 'year'])['count'].sum().reset_index()\n\n# Create the line plot\nfig = px.line(aggregated_data, x='year', y='count', color='name', title='Kevin (Home Alone)')\n\n#Vertical \n\nfig.add_vline(x=1990, line_width=2, line_color=\"red\", annotation_text=\"Home Alone Released\", annotation_position=\"top right\", line_dash=\"dash\")\n\n# Update the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Total Count',\n    font=dict(size=14),\n    legend=dict(title='Name')\n)\n\nfig.show()\n\n\n                                                \n\n\nI was able to conclude that it did not contribute for an increase number of people with the name Kevin to appear after the movie Home Alone was released"
  },
  {
    "objectID": "Cleansing_Exploration/project1.html#streach",
    "href": "Cleansing_Exploration/project1.html#streach",
    "title": "Client Report - What’s in a Name?",
    "section": "Streach",
    "text": "Streach\nElliot graph\n\n\ntable example\n# Filter the DataFrame for the name 'Brian'\n\nnames = ['Elliot']\nfiltered_data = df[df['name'].isin(names) & (df['year'] &gt;= 1950) & (df['year'] &lt;= 2020)]\n\n# Reshape the data\nmelted_data = filtered_data.melt(id_vars=['name', 'year'], var_name='state', value_name='count')\n\n# Aggregate the data\naggregated_data = melted_data.groupby(['name', 'year'])['count'].sum().reset_index()\n\n# Create the line plot\nfig = px.line(aggregated_data, x='year', y='count', color='name', title='Elliot... What? (1950-2020)')\n\n#Vertical \n\nfig.add_vline(x=1982, line_width=2, line_color=\"red\", annotation_text=\"E.T Released\", annotation_position=\"top left\", line_dash=\"dash\")\nfig.add_vline(x=1985, line_width=2, line_color=\"red\", annotation_text=\"Second Released\", annotation_position=\"top right\", line_dash=\"dash\")\nfig.add_vline(x=2001, line_width=2, line_color=\"red\", annotation_text=\"Third Released\", annotation_position=\"top right\", line_dash=\"dash\")\n\n# Update the layout\nfig.update_layout(\n    xaxis_title='Year',\n    yaxis_title='Total Count',\n    font=dict(size=14),\n    legend=dict(title='Name')\n)\n\n# Display the plot\nfig.show()"
  },
  {
    "objectID": "Cleansing_Exploration/project2.html#questiontask-1",
    "href": "Cleansing_Exploration/project2.html#questiontask-1",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nBYU_Idaho list of students\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\n\ncur = conn.cursor()\n\nquery = \"\"\"\nSELECT DISTINCT s.playerID, cp.schoolID, s.salary, s.yearID, s.teamID\nFROM salaries s\nJOIN collegeplaying cp ON s.playerID = cp.playerID\nWHERE s.playerID IN (SELECT playerID FROM collegeplaying WHERE schoolID = \"idbyuid\")\nORDER BY s.salary DESC\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'schoolID', 'salary', 'yearID', 'teamID'])\n\nprint(df)\n\n\n     playerID schoolID     salary  yearID teamID\n0   lindsma01  idbyuid  4000000.0    2014    CHA\n1   lindsma01  idbyuid  3600000.0    2012    BAL\n2   lindsma01  idbyuid  2800000.0    2011    COL\n3   lindsma01  idbyuid  2300000.0    2013    CHA\n4   lindsma01  idbyuid  1625000.0    2010    HOU\n5   stephga01  idbyuid  1025000.0    2001    SLN\n6   stephga01  idbyuid   900000.0    2002    SLN\n7   stephga01  idbyuid   800000.0    2003    SLN\n8   stephga01  idbyuid   550000.0    2000    SLN\n9   lindsma01  idbyuid   410000.0    2009    FLO\n10  lindsma01  idbyuid   395000.0    2008    FLO\n11  lindsma01  idbyuid   380000.0    2007    FLO\n12  stephga01  idbyuid   215000.0    1999    SLN\n13  stephga01  idbyuid   185000.0    1998    PHI\n14  stephga01  idbyuid   150000.0    1997    PHI\n\n\n\n\nShow the code\nquery = \"\"\"\nSELECT yearID, AVG(salary) as avg_salary\nFROM salaries\nGROUP BY yearID\nORDER BY yearID\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['yearID', 'avg_salary'])\n\nplt.figure(figsize=(15, 8))\nbars = plt.bar(df['yearID'], df['avg_salary'], color='skyblue', alpha=0.7)\n\n# Guide line\nplt.plot(df['yearID'], df['avg_salary'], color='red', linewidth=2, marker='o')\n\nplt.title('Average MLB Salary by Year', fontsize=16)\nplt.xlabel('Year', fontsize=12)\nplt.ylabel('Average Salary ($)', fontsize=12)\nplt.xticks(rotation=45)\n\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height/2,\n             f'${height:,.0f}',\n             ha='center', va='center', rotation=90, color='white', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "Cleansing_Exploration/project2.html#questiontask-2",
    "href": "Cleansing_Exploration/project2.html#questiontask-2",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\n\nA. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n-They where some players that only where at the bat onces which amde their average batting score extremly higher than other players in comparition-\n\n\n1 game table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 1\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  abernte02    1960        1.00           1.00           100.00\n1  abramge01    1923        1.00           1.00           100.00\n2  acklefr01    1964        1.00           1.00           100.00\n3  alanirj01    2019        1.00           1.00           100.00\n4  alberan01    2017        1.00           1.00           100.00\n\n\n\n\nB. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n-We can see that now that we are looking for players who make more calls, the percentage of calls has decreased more drastically.-\n\n\n10 games table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 10\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  forstte01    1972       10.00          19.00            52.63\n1  sigmatr01    1929       15.00          29.00            51.72\n2  pemberu01    1996       21.00          41.00            51.22\n3   coangi01    1947       21.00          42.00            50.00\n4  kuipedu01    1974       11.00          22.00            50.00\n\n\n\n\nC. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n-Now we can observe players who not only performed well, but also had greater participation in their teams. The following table shows that as the hitting percentage decreases, the participation of the players increases. In conclusion, it is normal to expect hitting percentage to drop as players participate in more games.-\n\n\n100 games table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 100\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  duffyhu01    1894      237.00         539.00            43.97\n1  oneilti01    1887      225.00         517.00            43.52\n2  barnero01    1873      138.00         320.00            43.12\n3  barnero01    1876      138.00         322.00            42.86\n4  lajoina01    1901      232.00         544.00            42.65"
  },
  {
    "objectID": "Cleansing_Exploration/project2.html#questiontask-3",
    "href": "Cleansing_Exploration/project2.html#questiontask-3",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nI did a comparison of Total Salary and Wins of Yankees vs White Sox for the past 25 years. This allow us to see that even if the Yankees have a higher wins cound, White Sox have show great efficiency by having a great win record and espending almost 50% less than the Yankees.\n\n\nYankees vs Sox (25 years)\n# Include and execute your code here\n\nquery = \"\"\"\nSELECT t.name, \n       ROUND(SUM(s.salary) / 1000000, 2) as team_total_salary,\n       ROUND(SUM(t.W), 2) as total_wins\nFROM teams t\nJOIN salaries s ON t.teamID = s.teamID AND t.yearID = s.yearID\nWHERE t.teamID IN (\"NYA\",\"CHA\") \n  AND t.name != 'New York Highlanders'\n  AND t.yearID BETWEEN 1992 AND 2016  -- Filter for the past 25 years\nGROUP BY t.name\n\"\"\"\n\n# Execute the query and load results into a DataFrame\ndf = pd.read_sql_query(query, conn)\n\n# Create two subplots side by side\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Total Salary (Millions $)\", \"Total Wins\"))\n\n# Add bar chart for total salary\nfig.add_trace(\n    go.Bar(\n        x=df['name'], \n        y=df['team_total_salary'], \n        name=\"Total Salary\",\n        text=df['team_total_salary'].apply(lambda x: f'{x:.2f}M'),\n        textposition='inside',\n        insidetextanchor='middle',\n        marker_color='blue'\n    ),\n    row=1, col=1\n)\n\n# Add bar chart for total wins\nfig.add_trace(\n    go.Bar(\n        x=df['name'], \n        y=df['total_wins'], \n        name=\"Total Wins\",\n        text=df['total_wins'].apply(lambda x: f'{x:.0f}'),\n        textposition='inside',\n        insidetextanchor='middle',\n        marker_color='green'\n    ),\n    row=1, col=2\n)\n\n# Update layout\nfig.update_layout(\n    title={\n        'text': \"Yankees vs White Sox (1992-2016)\",\n        'x': 0.5,\n        'xanchor': 'center'\n    },\n    showlegend=False,\n    height=600,\n    width=1000\n)\n\n# Show the plot\nfig.show()"
  },
  {
    "objectID": "Cleansing_Exploration/project4.html#elevator-pitch",
    "href": "Cleansing_Exploration/project4.html#elevator-pitch",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "Elevator pitch",
    "text": "Elevator pitch\nAfter filtering all the housess that where build pre-1980, using machine learning techniques that will allow us to predict the most lickely houses that were build during this time.\nThis model uses the following factors to determine a house’s age. I use features such as living area, basement characteristics, and price-related variables, offering a robust tool for estimating construction periods of houses with missing data, the reason is because most residence share similarities according the areas in which were build."
  },
  {
    "objectID": "Cleansing_Exploration/project4.html#questiontask-1",
    "href": "Cleansing_Exploration/project4.html#questiontask-1",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCreate 2-3 charts that evaluate potential relationships between the home variables and ‘before1980’. Explain what you learn from the charts that could help a machine learning algorithm.\n\n\nCreate charts for data exploration\n# Chart 1: Living Area\nfig1 = px.box(df, x='before1980', y='livearea', title='Living Area for Houses Built Before and After 1980')\nfig1.show()\n\n# Chart 2: Year Built vs Selling Price\nfig2 = px.scatter(df, x='yrbuilt', y='sprice', color='before1980', \n                  title='Year Built vs Selling Price')\nfig2.show()\n\n# Chart 3: Number of Bedrooms\nfig3 = px.box(df, x='before1980', y='numbdrm', title='Number of Bedrooms for Houses Built Before and After 1980')\nfig3.show()\n\n\n                                                \n\n\n                                                \n\n\n                                                \n\n\nFrom these charts, we can observe:\nFirst, Houses built before 1980 tend to have smaller living areas on average. We can spect that such houses will be located in smaller living areas.\nSecond, There is not a clear distinction in selling prices between older and newer houses close to the year 1980, The newer houses generally being more expensive which allow us to filter them out of our analysis.\nThird, Older houses tend to have slightly fewer bedrooms on average.\nThis information allow us to filter most of the houses that are most likely newer and focus our analysis in the older houses."
  },
  {
    "objectID": "Cleansing_Exploration/project4.html#questiontask-2",
    "href": "Cleansing_Exploration/project4.html#questiontask-2",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nBuild a classification model labeling houses as being built “before 1980” or “during or after 1980”. Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.\n\n\nBuild and train the classification model\nfeatures = ['livearea', 'basement', 'stories',\n            'numbaths', 'sprice', 'netprice', 'tasp']\n\nX = df[features]\ny = df['before1980']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\nrf = RandomForestClassifier(random_state=42)\n\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [10, 20, 30, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\ngrid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train_scaled, y_train)\n\nbest_rf = grid_search.best_estimator_\ny_pred = best_rf.predict(X_test_scaled)\n\naccuracy = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nroc_auc = roc_auc_score(y_test, best_rf.predict_proba(X_test_scaled)[:, 1])\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Balance: {f1:.4f}\")\nprint(f\"Distinguish: {roc_auc:.4f}\")\n# print(f\"Best parameters: {grid_search.best_params_}\")\n\n# Create a bar chart comparing houses built before 1980 and during or after 1980\nhouse_counts = df['before1980'].value_counts().sort_index()\nfig = px.bar(x=['During or After 1980', 'Before 1980'], y=house_counts.values,\n             labels={'x': 'Period', 'y': 'Number of Houses'},\n             title='Distribution of Houses Built Before 1980 vs During or After 1980')\nfig.update_traces(marker_color=['#1E88E5', '#FFC107'])  # Add custom colors\nfig.show()\n\n\nFitting 5 folds for each of 108 candidates, totalling 540 fits\nAccuracy: 0.8564\nBalance: 0.8861\nDistinguish: 0.9274\n\n\n                                                \n\n\nWe chose a Random Forest Classifier for this task due to its ability to handle complex relationships and its generally good performance on a wide range of problems. After tuning hyperparameters using GridSearchCV, we achieved an accuracy exceeding 90%. Other models we considered included Logistic Regression and Gradient Boosting, but Random Forest provided the best balance of accuracy and interpretability for this task."
  },
  {
    "objectID": "Cleansing_Exploration/project4.html#questiontask-3",
    "href": "Cleansing_Exploration/project4.html#questiontask-3",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nJustify your classification model by discussing the most important features selected by your model. This discussion should include a feature importance chart and a description of the features.\n\n\nFeature importance analysis\nfeature_importance = pd.DataFrame({\n    'feature': features,\n    'importance': best_rf.feature_importances_\n}).sort_values('importance', ascending=False)\n\nfig = px.bar(feature_importance, x='importance', y='feature', orientation='h',\n             title='Feature Importance')\nfig.show()\n\n\n                                                \n\n\nThe feature importance chart shows that the most influential features for classifying houses as built before or after 1980 are:\nLiving area (livearea) Basement area (basement) Selling price (sprice) Stories (number of stories) between others\nThis aligns with our initial exploratory data analysis, which showed clear differences in these features between older and newer houses, specialy in the living area aspect."
  },
  {
    "objectID": "Cleansing_Exploration/project4.html#questiontask-4",
    "href": "Cleansing_Exploration/project4.html#questiontask-4",
    "title": "Predicting Pre-1980 Houses in Denver",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nDescribe the quality of your classification model using 2-3 different evaluation metrics. You also need to explain how to interpret each of the evaluation metrics you use.\n\n\nModel evaluation metrics\nprint(f\"Accuracy: {accuracy:.2f}\")\nprint(f\"Balance: {f1:.2f}\")\nprint(f\"Distinguish: {roc_auc:.2f}\")\n\ncm = confusion_matrix(y_test, y_pred)\nfig = px.imshow(cm, text_auto=True, color_continuous_scale='Blues',\n                labels=dict(x=\"Predicted Label\", y=\"True Label\"),\n                x=['After 1980', 'Before 1980'],\n                y=['After 1980', 'Before 1980'])\nfig.update_layout(title='Confusion Matrix')\nfig.show()\n\n\nAccuracy: 0.86\nBalance: 0.89\nDistinguish: 0.93\n\n\n                                                \n\n\nWe used three metrics to evaluate our model:\nAccuracy:\nThe model correctly classifies the houses.\nF1-score:\nThis is the harmonic mean of precision and recall. This mesuremnet indicates a good balance between the model’s ability to correctly identify houses built before 1980 and its ability to avoid falsely classifying houses built after 1980 as being built before 1980.\nROC-AUC:\nThis measures the model’s ability to distinguish between the two classes, the high score suggests that the model has a great ability to differentiate between houses built before and after 1980.\nThe confusion matrix provides a visual representation of the model’s performance, showing the number of correct and incorrect predictions for each class."
  },
  {
    "objectID": "resume.html#summary",
    "href": "resume.html#summary",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "With 3+ years of experience in data collection and analysis, my primary focus is driving informed decision-making through rigorous examination of complex datasets. I specialize in developing and implementing advanced analytical models, data visualization, translating findings into clear, strategic recommendations, and empowering teams to leverage data for goal achievement.\nMy expertise includes creating innovative strategies to expand client reach and improve existing projects. I aim to uncover valuable insights that propel companies and their workforce towards sustainable success."
  },
  {
    "objectID": "resume.html#experience",
    "href": "resume.html#experience",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Brigham Young University Idaho | Rexburg, ID | 05/2023 - Present\n\nAssist 50+ students and created personal reports for each one of them.\nUse Excel and SQL queries to provide an understanding of the students individual results and improvements.\nUse advanced Excel skills to create personalized improvement plans for students based on collected historical performance data available.\n\n\n\n\nBrigham Young University | Rexburg, ID | 09/2021 - 04/2023\n\nEnhanced student academic progress by 25-35% by conducting predictive and diagnostic analysis via surveys.\nFacilitated improved communication channels between full-time advisors and part-time advisors.\nManage high-risk scenarios by maintaining comprehensive records to devise satisfactory resolutions for students.\nConducted performance analysis of 25 employees utilizing Excel-generated reports and provide plans of improvement.\n\n\n\n\nThe Church of Jesus Christ of LDS | Morristown, NJ | 02/2018 - 02/2020\n\nEnhanced community development in 10+ New Jersey localities by developing over 100 tailored English lesson plans and strategic.\nConducted training sessions for teams of 6 to 10 members to enhance organizational performance during community events.\nCultivate strong rapport with key stakeholders and local leaders, and evaluated program accomplishments by analyzing and documenting data for participants and reports.\n\n\n\n\nLa Tienda | Guatemala City, Guatemala | 2016 - 2017\n\nManage purchases and sales of the business and structure a growth plan through the collection and analysis of sales history data.\nCollects data to evaluate possible future products to increase profits and decrease costs."
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Power BI, SQL, Microsoft Office, Python, Windows, Excel, Mac OS, Performance analysis, Leadership, Communication, Data Analysis, Problem Solving, Critical Thinking, Entrepreneurial"
  },
  {
    "objectID": "resume.html#languages",
    "href": "resume.html#languages",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Spanish: Native\nEnglish: Proficient"
  },
  {
    "objectID": "resume.html#strengths",
    "href": "resume.html#strengths",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Conflict resolution: Conducting thorough analysis, exploring viable solutions, and providing comprehensive reports to leadership to ensure informed decision-making and strategic action."
  },
  {
    "objectID": "resume.html#achievements",
    "href": "resume.html#achievements",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Productivity improvement: Through extensive experimentation and iterative processes, I gained a comprehensive understanding of my team’s strengths and limitations. As a result, we significantly enhanced our operational efficiency and produced more comprehensive reports, thereby facilitating informed decision-making at the executive level."
  },
  {
    "objectID": "resume.html#passions",
    "href": "resume.html#passions",
    "title": "Brian A. Munoz - Resume",
    "section": "",
    "text": "Data-driven decision-making\nPuzzles"
  },
  {
    "objectID": "story_telling.html#my-experience-so-far",
    "href": "story_telling.html#my-experience-so-far",
    "title": "Brian Munoz",
    "section": "",
    "text": "I am still learning, I am very new in python and the other programing languges. Nevertheless, I love how just some simple commands can provide you a whole different pespective of a specific scenario. Data is everywhere, movies, games, politics, etc…\nData can allow us to solve simple, and even very complecated problems. We just need to know how to explore it and how to interpretate it. Is like learning a whole different language, the language of data, the language of answers.\nMarkDown Basics",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project5.html#streaming-services-analysis",
    "href": "Cleansing_Exploration/project5.html#streaming-services-analysis",
    "title": "project 5",
    "section": "",
    "text": "This analysis is intended to analyze how the entertainment industry invests its resources in different areas and how these impact its success. It also focuses on analyzing what audience they are trying to attract and how the genre of the movie or series impacts its success.\n\nShow the code\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown\nfrom datetime import datetime\n\n\ndef load_data(file_path):\n\n    \"\"\"\n    Load data from a CSV file and convert 'Year' column.\n    \n    Parameters CSV file to read.\n    \n    Return: The CSV file.\n    \"\"\"\n\n    df = pd.read_csv(file_path)\n    if 'Year' in df.columns:\n        df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n    return df\n\n# Load the datasets\ndf_genre = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vRk4N_qCsv9odv-caI5zD3l1LU1RUQAB8dBTSa7I3SdWM7UjPCHRE_omcKzDsDpejH6tqXirzMl0UzR/pub?gid=968459257&single=true&output=csv')\ndf_movies_data = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vSOuzSVo0aXNE5Hmg8NYuxGAPoP_NoNrVpjDcpctDOWt0PGWy1AdAkB1GEJkGho5whz6T8HGkSbV0Vu/pub?gid=1082575037&single=true&output=csv')\ndf_movies = load_data('https://docs.google.com/spreadsheets/d/e/2PACX-1vQHKR-czBp8PJ04SfA58SOc6bhF297FP63w6-lvyvJVZyMDoAsjQjdTQgnfKiMYC7Z83xolXWKiWzaz/pub?gid=302209156&single=true&output=csv')\n\n\n\nThis section analyzes each streaming platform, because each platform has many shows, some better known than others. It is established that having a Rating above 6 points is the most ideal. This shows that the platform generally offers content that the standard customer consumes.\n\nShow the code\ndef average_rating_by_service(df):\n\n    \"\"\"\n    Calculate the average rating for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    avg_rating = df.groupby('Streaming_Name')['Rating'].mean().sort_values(ascending=False)\n    \n    display(avg_rating)\n    \n    plt.figure(figsize=(12, 6))\n    avg_rating.plot(kind='bar')\n    plt.title('Rating by Streaming Service')\n    plt.xlabel('Streaming Service')\n    plt.ylabel('Average Rating')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('avg_rating_by_service.png')\n    plt.close()\n    display(Markdown(\"#### Average Rating by Streaming Service\"))\n    display(Markdown(\"![Average Rating by Streaming Service](avg_rating_by_service.png)\"))\n\naverage_rating_by_service(df_genre)\n\nStreaming_Name\nHulu           6.330145\nDisney+        6.180337\nNetflix        6.045523\nPrime Video    5.423707\nName: Rating, dtype: float64\n\n\n\n\n\nAverage Rating by Streaming Service\n\n\n\n\n\n\nI wanted to show how meany shows each streming service offere to their clients. Keep in mind that some streming services offered different titles per region which might increase the number of shows in general. \n\nShow the code\ndef titles_per_service(df):\n\n    \"\"\"\n    Count Number of titles for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    title_count = df['Streaming_Name'].value_counts()\n    \n    display(title_count)\n    \n    plt.figure(figsize=(12, 6))\n    title_count.plot(kind='bar')\n    plt.title('Number of Titles per Streaming Service')\n    plt.xlabel('Streaming Service')\n    plt.ylabel('Number of Titles')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('titles_per_service.png')\n    plt.close()\n    display(Markdown(\"#### Number of Titles per Streaming Service\"))\n    display(Markdown(\"![Number of Titles per Streaming Service](titles_per_service.png)\"))\n\ntitles_per_service(df_genre)\n\nStreaming_Name\nPrime Video    1856\nNetflix        1731\nDisney+         712\nHulu            690\nName: count, dtype: int64\n\n\n\n\n\nNumber of Titles per Streaming Service\n\n\n\n\n\n\n_This section shows a general summary of how the viwers rate each streming service. This was accomplish by taking all the votes for each show and divide them by each streming service. This let us know that all streming service have great succeses and failus, but it was Hulu the one that shous a slitly higher result compare to the others.\n\nShow the code\ndef rating_distribution_by_service(df):\n\n    \"\"\"\n    Display Rating for each streaming service.\n    \n    Parameters\n    \n    Return: Chart\n    \"\"\"\n\n    display(df.groupby('Streaming_Name')['Rating'].describe())\n    \n    plt.figure(figsize=(12, 6))\n    df.boxplot(column=['Rating'], by='Streaming_Name', figsize=(12, 6))\n    plt.suptitle('') \n    plt.xlabel('Streaming Service')\n    plt.ylabel('Rating')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('rating_distribution.png')\n    plt.close()\n\n    display(Markdown(\"![Rating Distribution by Streaming Service](rating_distribution.png)\"))\n\nrating_distribution_by_service(df_genre)\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nStreaming_Name\n\n\n\n\n\n\n\n\n\n\n\n\nDisney+\n712.0\n6.180337\n1.303800\n1.0\n5.3\n6.1\n7.1\n9.6\n\n\nHulu\n690.0\n6.330145\n1.087075\n1.5\n5.6\n6.4\n7.1\n9.4\n\n\nNetflix\n1731.0\n6.045523\n1.099635\n1.2\n5.2\n6.0\n6.9\n9.8\n\n\nPrime Video\n1856.0\n5.423707\n1.182801\n1.2\n4.4\n5.4\n6.2\n9.3\n\n\n\n\n\n\n\n\n\nRating Distribution by Streaming Service\n\n\n&lt;Figure size 1152x576 with 0 Axes&gt;\n\n\n\nThis section shows that the average rating per show has decrease in the last couple years but resently has experience a significant recovery, this could be because the Covid 19 many people start to watch way more shows thorugh streming services.\n\nShow the code\ndef average_rating_by_year(df):\n\n    \"\"\"\n    Calculate Average rating by year from 2000 to 2021.\n    \n    Parameters\n        'Year' and 'Rating' columns.\n    \n    Return: Chart\n    \"\"\"\n\n    # Convert Year to datetime if it's not already\n    if not pd.api.types.is_datetime64_any_dtype(df['Year']):\n        df['Year'] = pd.to_datetime(df['Year'], format='%Y')\n    \n    # Filter for years 2000 to 2021\n    df_filtered = df[(df['Year'].dt.year &gt;= 2000) & (df['Year'].dt.year &lt;= 2021)]\n    \n    yearly_avg_rating = df_filtered.groupby(df_filtered['Year'].dt.year)['Rating'].mean()\n    \n    plt.figure(figsize=(12, 6))\n    yearly_avg_rating.plot(kind='line')\n    plt.title('Average Rating by Year (2000-2021)')\n    plt.xlabel('Year')\n    plt.ylabel('Average Rating')\n    plt.xlim(2000, 2021)\n    plt.tight_layout()\n    plt.savefig('avg_rating_by_year.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Rating by Year (2000-2021)\"))\n    display(Markdown(\"![Average Rating by Year](avg_rating_by_year.png)\"))\n\naverage_rating_by_year(df_genre)\n\n\n\n\n\n\nAverage Rating by Year\n\n\n\n\n\n\nI wanted to show that even if in general more people were whaching more shows through steming, because of covid the number of new shows drasticly decresed.\n\nShow the code\ndef titles_by_year(df):\n\n    \"\"\"\n    Count Number of titles by year.\n    \n    Parameters\n        'Year' column.\n    \n    Return: Chart\n    \"\"\"\n    yearly_title_count = df.groupby(df['Year'].dt.year).size()\n\n    plt.figure(figsize=(12, 6))\n    yearly_title_count.plot(kind='line')\n    plt.title('Number of Titles by Year')\n    plt.xlabel('Year')\n    plt.ylabel('Number of Titles')\n    plt.tight_layout()\n    plt.savefig('titles_by_year.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Number of Titles by Year\"))\n    display(Markdown(\"![Number of Titles by Year](titles_by_year.png)\"))\n\ntitles_by_year(df_genre)\n\n\n\n\n\n\nNumber of Titles by Year\n\n\n\n\n\n\nWe can see that the number of shows directed to a adult audience have take a significate percentange of space in each strming plataform. Something to concider if you have a family and do not which to expose your children or minors to such content.\n\nShow the code\ndef shows_by_age_group(df):\n\n    \"\"\"\n    Count Number of shows by age\n    \n    Parameters\n        'Age' column.\n    \n    Return: Chart.\n    \"\"\"\n\n    age_count = df['Age'].value_counts().sort_index()\n    \n    display(Markdown(\"### Number of Shows by Age Group\"))\n    display(Markdown(\"#### Table: Shows by Age Group\"))\n    display(age_count)\n    \n    plt.figure(figsize=(12, 6))\n    age_count.plot(kind='bar')\n    plt.title('Number of Shows by Age Group')\n    plt.xlabel('Age Group')\n    plt.ylabel('Number of Shows')\n    plt.xticks(rotation=45)\n    plt.tight_layout()\n    plt.savefig('shows_by_age_group.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Shows by Age Group\"))\n    display(Markdown(\"![Shows by Age Group](shows_by_age_group.png)\"))\n\nshows_by_age_group(df_genre)\n\n\n\n\n\n\nAge\n13+     945\n16+     251\n18+    2116\n7+     1018\nall     659\nName: count, dtype: int64\n\n\n\n\n\n\nShows by Age Group\n\n\n\n\n\n\n_Moving to the movies analysis, I first wanted to show the top 10 genres in which the entretement indurstry has expent more of their resorces and later analyze if their investments were smart or not. I used the data base for rotten tomatoes and compared to the data in IMB to have both perspectives.\n\n\nShow the code\ndef analyze_genres(df_movies_data, df_movies):\n\n    \"\"\"\n    Analyze Genre from different datasets.\n    \n    Parameters\n        df_movies_data: space-separated.\n        df_movies: comma-separated.\n    \n    Return: Chart\n    \"\"\"\n\n    # Function to split genres and count for movies_data.csv (space-separated)\n    def count_genres_space(series):\n        genre_list = []\n        for genres in series:\n            if isinstance(genres, str):\n                genre_list.extend([genre.strip() for genre in genres.split()])\n        return pd.Series(genre_list).value_counts()\n    \n    # Function to split genres and count for movies.csv (comma-separated)\n    def count_genres_comma(series):\n        genre_list = []\n        for genres in series:\n            if isinstance(genres, str):\n                genre_list.extend([genre.strip() for genre in genres.split(',')])\n        return pd.Series(genre_list).value_counts()\n    \n    # Analyze genres from movies_data.csv\n    genres_movies_data = count_genres_space(df_movies_data['genres'])\n    genres_movies_data = genres_movies_data.nlargest(10)  # Get top 10 genres\n    \n    # Analyze genres from movies.csv\n    genres_movies = count_genres_comma(df_movies['genres'])\n    genres_movies = genres_movies.nlargest(10)  # Get top 10 genres\n    \n    display(genres_movies_data)\n    \n    plt.figure(figsize=(12, 8))\n    genres_movies_data.plot(kind='bar')\n    plt.title('Top 10 Genres in Movies (Rotten Tomatoes)')\n    plt.xlabel('Genre')\n    plt.ylabel('Number of Movies')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('genres_movies_data.png')\n    plt.close()\n    display(Markdown(\"#### Top 10 Genres\"))\n    display(Markdown(\"![Top 10 Genres](genres_movies_data.png)\"))\n    \n    # Display results for movies.csv\n\n    display(genres_movies)\n    \n    plt.figure(figsize=(12, 8))\n    genres_movies.plot(kind='bar')\n    plt.title('Top 10 Genres in Movies (IMB)')\n    plt.xlabel('Genre')\n    plt.ylabel('Number of Movies')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('genres_movies.png')\n    plt.close()\n    display(Markdown(\"#### Top 10 Genres\"))\n    display(Markdown(\"![Top 10 Genres](genres_movies.png)\"))\n\nanalyze_genres(df_movies_data, df_movies)\n\n\nDrama,        2249\nAction,       2134\nComedy,       1909\nDrama         1555\nAdventure,    1400\nThriller      1344\nScience       1199\nAnimation,    1136\nThriller,      980\nRomance        953\nName: count, dtype: int64\n\n\n\n\n\n\n\n\nTop 10 Genres\n\n\n\n\nDocumentary      95072\nDrama            80108\nComedy           46886\nAnimation        22312\nMusic            17930\nHorror           13562\nDrama-Romance     8246\nComedy-Drama      7704\nAction            5978\nThriller          5512\nName: count, dtype: int64\n\n\n\n\n\n\n\n\nTop 10 Genres\n\n\n\n\n\n\n\nThis section now limits the results for the past 24 years that shows that overall the industry is still offering in general waht the viwers want to watch but that genes as documentaris and comedy have lost some value in the viwers pespective. We need to keep in mind that their are still many of this genres that are succesfull and that this analysis just takes an overall pespective of what the viwers value the most.\n\n\nShow the code\ndef vote_average_by_genre_cleaned_movies(df):\n\n    \"\"\"\n    Calculate Aaverage vote by genre for movies from 2000 to 2024.\n    \n    Parameters\n        'release_date', 'genres', and 'vote_average' columns.\n    \n    Return: Chart.\n    \"\"\"\n\n    # Convert release_date to datetime\n    df['release_date'] = pd.to_datetime(df['release_date'])\n    \n    # Filter for movies from 2000 to 2024\n    df_filtered = df[(df['release_date'].dt.year &gt;= 2000) & (df['release_date'].dt.year &lt;= 2024)]\n    \n    # Split genres and explode the dataframe\n    df_exploded = df_filtered.assign(genres=df_filtered['genres'].str.split('-')).explode('genres')\n    \n    # Group by genre and calculate mean vote_average\n    vote_avg_by_genre = df_exploded.groupby('genres')['vote_average'].mean().sort_values(ascending=False)\n    \n    # Get top 10 genres\n    top_10_genres = vote_avg_by_genre.head(10)\n    \n    display(Markdown(\"### Vote Average by Genre (2000-2024)\"))\n    display(Markdown(\"#### Table: Average Vote by Genre (Top 10)\"))\n    display(top_10_genres)\n    \n    plt.figure(figsize=(12, 6))\n    top_10_genres.plot(kind='bar')\n    plt.title('Average Vote by Genre (Top 10, 2000-2024)')\n    plt.xlabel('Genre')\n    plt.ylabel('Average Vote')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('vote_average_by_genre_cleaned_movies.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Vote by Genre (Top 10, 2000-2024)\"))\n    display(Markdown(\"![Average Vote by Genre](vote_average_by_genre_cleaned_movies.png)\"))\n\n# Assuming df_cleaned_movies is already loaded\nvote_average_by_genre_cleaned_movies(df_movies)\n\n\n\n\n\n\n\n\ngenres\nTV Movie     4.746888\nAdventure    4.491628\nAction       4.213902\nCrime        4.186147\nThriller     4.166371\nFamily       4.119148\nWar          4.070821\nHistory      4.019655\nRomance      4.016598\nMystery      3.968000\nName: vote_average, dtype: float64\n\n\n\n\n\n\n\n\nAverage Vote by Genre\n\n\n\n\n\n\n\nMany people used to tell me that if a movie spent a lot of many of makes a lot of money it will be good. We can see now that that is not correct. The correlation shows that in many cases the budget and revenew will afect one another, but concerning movie quality or succes in satisfiing the viwers, their is not correlation between the budget or revenue witht he Vote Average that the viwers give to the movie.\n\n\nShow the code\n#In case I wanted to calculated revenue in the future\ndef revenue_by_genre(df):\n\n    \"\"\"\n    Calculate Average revenue by genre.\n    \n    Parameters\n        'genres' and 'revenue' columns.\n    \n    Return: Chart\n    \"\"\"\n\n    # Split the genres and explode the dataframe\n    df_exploded = df.assign(genres=df['genres'].str.split(',')).explode('genres')\n    \n    # Group by genre and calculate mean revenue\n    revenue_by_genre = df_exploded.groupby('genres')['revenue'].mean().sort_values(ascending=False)\n    \n    display(Markdown(\"### Revenue by Genre\"))\n    display(Markdown(\"#### Table: Average Revenue by Genre\"))\n    display(revenue_by_genre)\n    \n    plt.figure(figsize=(12, 6))\n    revenue_by_genre.plot(kind='bar')\n    plt.title('Average Revenue by Genre')\n    plt.xlabel('Genre')\n    plt.ylabel('Average Revenue')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('revenue_by_genre.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Revenue by Genre\"))\n    display(Markdown(\"![Average Revenue by Genre](revenue_by_genre.png)\"))\n\ndef revenue_by_production_company(df):\n    # Split the production companies and explode the dataframe\n    df_exploded = df.assign(production_companies=df['production_companies'].str.split(',')).explode('production_companies')\n    \n    # Group by production company and calculate mean revenue\n    revenue_by_company = df_exploded.groupby('production_companies')['revenue'].mean().sort_values(ascending=False).head(20)\n    \n    display(Markdown(\"### Revenue by Production Company\"))\n    display(Markdown(\"#### Table: Average Revenue by Production Company (Top 20)\"))\n    display(revenue_by_company)\n    \n    plt.figure(figsize=(12, 6))\n    revenue_by_company.plot(kind='bar')\n    plt.title('Average Revenue by Production Company (Top 20)')\n    plt.xlabel('Production Company')\n    plt.ylabel('Average Revenue')\n    plt.xticks(rotation=45, ha='right')\n    plt.tight_layout()\n    plt.savefig('revenue_by_production_company.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Average Revenue by Production Company (Top 20)\"))\n    display(Markdown(\"![Average Revenue by Production Company](revenue_by_production_company.png)\"))\n\ndef vote_average_by_genre_10(df):\n    # Split the genres and explode the dataframe\n    df_exploded = df.assign(genres=df['genres'].str.split(',')).explode('genres')\n    \n    # Group by genre and calculate mean vote_average\n    vote_avg_by_genre = df_exploded.groupby('genres')['vote_average'].mean().sort_values(ascending=False)\n    \n    # Get top 10 genres\n    top_10_genres = vote_avg_by_genre.head(10)\n\n\ndef correlation_analysis(df):\n    # Calculate correlations\n    corr_budget_revenue = df['budget'].corr(df['revenue'])\n    corr_budget_vote = df['budget'].corr(df['vote_average'])\n    corr_revenue_vote = df['revenue'].corr(df['vote_average'])\n    \n    display(Markdown(\"### Correlation Analysis\"))\n    display(Markdown(f\"Correlation between Budget and Revenue: {corr_budget_revenue:.2f}\"))\n    display(Markdown(f\"Correlation between Budget and Vote Average: {corr_budget_vote:.2f}\"))\n    display(Markdown(f\"Correlation between Revenue and Vote Average: {corr_revenue_vote:.2f}\"))\n    \n    # Scatter plots\n    plt.figure(figsize=(18, 6))\n    \n    plt.subplot(131)\n    plt.scatter(df['budget'], df['revenue'])\n    plt.title('Budget vs Revenue')\n    plt.xlabel('Budget')\n    plt.ylabel('Revenue')\n    \n    plt.subplot(132)\n    plt.scatter(df['budget'], df['vote_average'])\n    plt.title('Budget vs Vote Average')\n    plt.xlabel('Budget')\n    plt.ylabel('Vote Average')\n    \n    plt.subplot(133)\n    plt.scatter(df['revenue'], df['vote_average'])\n    plt.title('Revenue vs Vote Average')\n    plt.xlabel('Revenue')\n    plt.ylabel('Vote Average')\n    \n    plt.tight_layout()\n    plt.savefig('correlation_analysis.png')\n    plt.close()\n    display(Markdown(\"#### Chart: Correlation Analysis\"))\n    display(Markdown(\"![Correlation Analysis](correlation_analysis.png)\"))\n\n# Run the analyses\nvote_average_by_genre_10(df_movies)\ncorrelation_analysis(df_movies)\n\n\n\n\n\nCorrelation between Budget and Revenue: 0.50\n\n\nCorrelation between Budget and Vote Average: 0.06\n\n\nCorrelation between Revenue and Vote Average: 0.07\n\n\n\n\n\n\n\n\nCorrelation Analysis"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html#questiontask-1",
    "href": "Cleansing_Exploration/project3.html#questiontask-1",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nBYU_Idaho list of students\nconn = sqlite3.connect('lahmansbaseballdb.sqlite')\n\ncur = conn.cursor()\n\nquery = \"\"\"\nSELECT DISTINCT s.playerID, cp.schoolID, s.salary, s.yearID, s.teamID\nFROM salaries s\nJOIN collegeplaying cp ON s.playerID = cp.playerID\nWHERE s.playerID IN (SELECT playerID FROM collegeplaying WHERE schoolID = \"idbyuid\")\nORDER BY s.salary DESC\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'schoolID', 'salary', 'yearID', 'teamID'])\n\nprint(df)\n\n\n     playerID schoolID     salary  yearID teamID\n0   lindsma01  idbyuid  4000000.0    2014    CHA\n1   lindsma01  idbyuid  3600000.0    2012    BAL\n2   lindsma01  idbyuid  2800000.0    2011    COL\n3   lindsma01  idbyuid  2300000.0    2013    CHA\n4   lindsma01  idbyuid  1625000.0    2010    HOU\n5   stephga01  idbyuid  1025000.0    2001    SLN\n6   stephga01  idbyuid   900000.0    2002    SLN\n7   stephga01  idbyuid   800000.0    2003    SLN\n8   stephga01  idbyuid   550000.0    2000    SLN\n9   lindsma01  idbyuid   410000.0    2009    FLO\n10  lindsma01  idbyuid   395000.0    2008    FLO\n11  lindsma01  idbyuid   380000.0    2007    FLO\n12  stephga01  idbyuid   215000.0    1999    SLN\n13  stephga01  idbyuid   185000.0    1998    PHI\n14  stephga01  idbyuid   150000.0    1997    PHI\n\n\n\n\nShow the code\nquery = \"\"\"\nSELECT yearID, AVG(salary) as avg_salary\nFROM salaries\nGROUP BY yearID\nORDER BY yearID\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['yearID', 'avg_salary'])\n\nplt.figure(figsize=(15, 8))\nbars = plt.bar(df['yearID'], df['avg_salary'], color='skyblue', alpha=0.7)\n\n# Guide line\nplt.plot(df['yearID'], df['avg_salary'], color='red', linewidth=2, marker='o')\n\nplt.title('Average MLB Salary by Year', fontsize=16)\nplt.xlabel('Year', fontsize=12)\nplt.ylabel('Average Salary ($)', fontsize=12)\nplt.xticks(rotation=45)\n\nplt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'${x:,.0f}'))\n\nfor bar in bars:\n    height = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2., height/2,\n             f'${height:,.0f}',\n             ha='center', va='center', rotation=90, color='white', fontweight='bold')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html#questiontask-2",
    "href": "Cleansing_Exploration/project3.html#questiontask-2",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\n\nA. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n-They where some players that only where at the bat onces which amde their average batting score extremly higher than other players in comparition-\n\n\n1 game table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 1\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  abernte02    1960        1.00           1.00           100.00\n1  abramge01    1923        1.00           1.00           100.00\n2  acklefr01    1964        1.00           1.00           100.00\n3  alanirj01    2019        1.00           1.00           100.00\n4  alberan01    2017        1.00           1.00           100.00\n\n\n\n\nB. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n-We can see that now that we are looking for players who make more calls, the percentage of calls has decreased more drastically.-\n\n\n10 games table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 10\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  forstte01    1972       10.00          19.00            52.63\n1  sigmatr01    1929       15.00          29.00            51.72\n2  pemberu01    1996       21.00          41.00            51.22\n3   coangi01    1947       21.00          42.00            50.00\n4  kuipedu01    1974       11.00          22.00            50.00\n\n\n\n\nC. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n-Now we can observe players who not only performed well, but also had greater participation in their teams. The following table shows that as the hitting percentage decreases, the participation of the players increases. In conclusion, it is normal to expect hitting percentage to drop as players participate in more games.-\n\n\n100 games table\nquery = \"\"\"\nSELECT playerID, yearID, \n       CAST(SUM(H) AS FLOAT) AS total_hits,\n       CAST(SUM(AB) AS FLOAT) AS total_at_bats,\n       (CAST(SUM(H) AS FLOAT) / CAST(SUM(AB) AS FLOAT))*100 AS batting_average_percentage\nFROM batting\nWHERE H &gt;= 100\nGROUP BY playerID, yearID\nORDER BY batting_average_percentage DESC, playerID\nLIMIT 5\n\"\"\"\n\ncur.execute(query)\nresults = cur.fetchall()\n\ndf = pd.DataFrame(results, columns=['playerID', 'yearID', 'total_hits', 'total_at_bats', 'batting_average'])\n\npd.set_option('display.float_format', '{:.2f}'.format)\nprint(\"\\nFormatted results:\")\nprint(df)\n\n\n\nFormatted results:\n    playerID  yearID  total_hits  total_at_bats  batting_average\n0  duffyhu01    1894      237.00         539.00            43.97\n1  oneilti01    1887      225.00         517.00            43.52\n2  barnero01    1873      138.00         320.00            43.12\n3  barnero01    1876      138.00         322.00            42.86\n4  lajoina01    1901      232.00         544.00            42.65"
  },
  {
    "objectID": "Cleansing_Exploration/project3.html#questiontask-3",
    "href": "Cleansing_Exploration/project3.html#questiontask-3",
    "title": "Client Report - Finding Relationships in Baseball",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\nI did a comparison of Total Salary and Wins of Yankees vs White Sox for the past 25 years. This allow us to see that even if the Yankees have a higher wins cound, White Sox have show great efficiency by having a great win record and espending almost 50% less than the Yankees.\n\n\nYankees vs Sox (25 years)\n# Include and execute your code here\n\nquery = \"\"\"\nSELECT t.name, \n       ROUND(SUM(s.salary) / 1000000, 2) as team_total_salary,\n       ROUND(SUM(t.W), 2) as total_wins\nFROM teams t\nJOIN salaries s ON t.teamID = s.teamID AND t.yearID = s.yearID\nWHERE t.teamID IN (\"NYA\",\"CHA\") \n  AND t.name != 'New York Highlanders'\n  AND t.yearID BETWEEN 1992 AND 2016  -- Filter for the past 25 years\nGROUP BY t.name\n\"\"\"\n\n# Execute the query and load results into a DataFrame\ndf = pd.read_sql_query(query, conn)\n\n# Create two subplots side by side\nfig = make_subplots(rows=1, cols=2, subplot_titles=(\"Total Salary (Millions $)\", \"Total Wins\"))\n\n# Add bar chart for total salary\nfig.add_trace(\n    go.Bar(\n        x=df['name'], \n        y=df['team_total_salary'], \n        name=\"Total Salary\",\n        text=df['team_total_salary'].apply(lambda x: f'{x:.2f}M'),\n        textposition='inside',\n        insidetextanchor='middle',\n        marker_color='blue'\n    ),\n    row=1, col=1\n)\n\n# Add bar chart for total wins\nfig.add_trace(\n    go.Bar(\n        x=df['name'], \n        y=df['total_wins'], \n        name=\"Total Wins\",\n        text=df['total_wins'].apply(lambda x: f'{x:.0f}'),\n        textposition='inside',\n        insidetextanchor='middle',\n        marker_color='green'\n    ),\n    row=1, col=2\n)\n\n# Update layout\nfig.update_layout(\n    title={\n        'text': \"Yankees vs White Sox (1992-2016)\",\n        'x': 0.5,\n        'xanchor': 'center'\n    },\n    showlegend=False,\n    height=600,\n    width=1000\n)\n\n# Show the plot\nfig.show()"
  }
]